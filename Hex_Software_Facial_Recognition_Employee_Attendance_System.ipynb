{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install Required Libraries and Dependencies"
      ],
      "metadata": {
        "id": "OZW9OVczcGO6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqSk3l1HY47Q",
        "outputId": "254b46f0-140e-4d3c-9a40-6adbef95caa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages for facial recognition and deep learning\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Install all necessary packages for the project\"\"\"\n",
        "    packages = [\n",
        "        'opencv-python',\n",
        "        'opencv-contrib-python',\n",
        "        'face-recognition',\n",
        "        'pillow',\n",
        "        'numpy',\n",
        "        'pandas',\n",
        "        'streamlit',\n",
        "        'streamlit-webrtc',\n",
        "        'aiortc',\n",
        "        'pydantic'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "\n",
        "install_packages()\n",
        "print(\"All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import All Required Libraries"
      ],
      "metadata": {
        "id": "38pUa_0kcLmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import core libraries for computer vision and data processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import os\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Import streamlit libraries for web application\n",
        "import streamlit as st\n",
        "from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration\n",
        "import streamlit.components.v1 as components\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2naH3ZZcJAR",
        "outputId": "f0e5855a-e341-4407-df16-2227460d2f0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-08 22:17:18.226 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
            "2026-01-08 22:17:18.238 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
            "2026-01-08 22:17:18.249 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
            "2026-01-08 22:17:18.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2026-01-08 22:17:18.627 No runtime found, using MemoryCacheStorageManager\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Database Initialization and Management"
      ],
      "metadata": {
        "id": "Q1X0PZi1cPQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SQLite database for storing employee information and attendance records\n",
        "\n",
        "class AttendanceDatabase:\n",
        "    \"\"\"\n",
        "    Handles all database operations for employee management and attendance tracking.\n",
        "    This class manages SQLite database connections and CRUD operations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, db_name='attendance.db'):\n",
        "        \"\"\"\n",
        "        Initialize database connection and create necessary tables if they don't exist.\n",
        "\n",
        "        Args:\n",
        "            db_name (str): Name of the SQLite database file\n",
        "        \"\"\"\n",
        "        self.db_name = db_name\n",
        "        self.connection = None\n",
        "        self.initialize_database()\n",
        "\n",
        "    def initialize_database(self):\n",
        "        \"\"\"Create database tables for employees and attendance records\"\"\"\n",
        "        try:\n",
        "            self.connection = sqlite3.connect(self.db_name)\n",
        "            cursor = self.connection.cursor()\n",
        "\n",
        "            # Create employees table to store employee information\n",
        "            cursor.execute('''\n",
        "                CREATE TABLE IF NOT EXISTS employees (\n",
        "                    employee_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    name TEXT NOT NULL,\n",
        "                    email TEXT UNIQUE NOT NULL,\n",
        "                    phone TEXT,\n",
        "                    department TEXT,\n",
        "                    face_encoding BLOB,\n",
        "                    registration_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "                )\n",
        "            ''')\n",
        "\n",
        "            # Create attendance table to log daily attendance\n",
        "            cursor.execute('''\n",
        "                CREATE TABLE IF NOT EXISTS attendance (\n",
        "                    attendance_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    employee_id INTEGER NOT NULL,\n",
        "                    check_in_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "                    check_out_time TIMESTAMP,\n",
        "                    date DATE,\n",
        "                    FOREIGN KEY(employee_id) REFERENCES employees(employee_id)\n",
        "                )\n",
        "            ''')\n",
        "\n",
        "            self.connection.commit()\n",
        "            print(\"Database initialized successfully!\")\n",
        "\n",
        "        except sqlite3.Error as e:\n",
        "            print(f\"Database error: {e}\")\n",
        "\n",
        "    def add_employee(self, name, email, phone, department, face_encoding):\n",
        "        \"\"\"\n",
        "        Add a new employee to the database with their face encoding.\n",
        "\n",
        "        Args:\n",
        "            name (str): Employee full name\n",
        "            email (str): Employee email address\n",
        "            phone (str): Employee phone number\n",
        "            department (str): Employee department\n",
        "            face_encoding (numpy.ndarray): Encoded facial features\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            face_encoding_blob = pickle.dumps(face_encoding)\n",
        "\n",
        "            cursor.execute('''\n",
        "                INSERT INTO employees (name, email, phone, department, face_encoding)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (name, email, phone, department, face_encoding_blob))\n",
        "\n",
        "            self.connection.commit()\n",
        "            return True\n",
        "\n",
        "        except sqlite3.IntegrityError:\n",
        "            print(f\"Email {email} already exists in database\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding employee: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_all_employees(self):\n",
        "        \"\"\"\n",
        "        Retrieve all employees from the database.\n",
        "\n",
        "        Returns:\n",
        "            list: List of tuples containing employee information\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            cursor.execute('SELECT employee_id, name, email, phone, department FROM employees')\n",
        "            return cursor.fetchall()\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving employees: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_face_encodings(self):\n",
        "        \"\"\"\n",
        "        Retrieve all face encodings from the database for recognition.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (list of encodings, list of employee_ids, list of names)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            cursor.execute('SELECT employee_id, name, face_encoding FROM employees')\n",
        "            results = cursor.fetchall()\n",
        "\n",
        "            encodings = []\n",
        "            employee_ids = []\n",
        "            names = []\n",
        "\n",
        "            for employee_id, name, face_encoding_blob in results:\n",
        "                encoding = pickle.loads(face_encoding_blob)\n",
        "                encodings.append(encoding)\n",
        "                employee_ids.append(employee_id)\n",
        "                names.append(name)\n",
        "\n",
        "            return encodings, employee_ids, names\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving face encodings: {e}\")\n",
        "            return [], [], []\n",
        "\n",
        "    def mark_attendance(self, employee_id):\n",
        "        \"\"\"\n",
        "        Record attendance for an employee with current timestamp.\n",
        "\n",
        "        Args:\n",
        "            employee_id (int): ID of the employee checking in\n",
        "\n",
        "        Returns:\n",
        "            bool: True if successful, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            current_date = datetime.now().date()\n",
        "\n",
        "            # Check if employee already checked in today\n",
        "            cursor.execute('''\n",
        "                SELECT attendance_id FROM attendance\n",
        "                WHERE employee_id = ? AND date = ? AND check_out_time IS NULL\n",
        "            ''', (employee_id, current_date))\n",
        "\n",
        "            if cursor.fetchone():\n",
        "                print(\"Employee already checked in today\")\n",
        "                return False\n",
        "\n",
        "            cursor.execute('''\n",
        "                INSERT INTO attendance (employee_id, date)\n",
        "                VALUES (?, ?)\n",
        "            ''', (employee_id, current_date))\n",
        "\n",
        "            self.connection.commit()\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error marking attendance: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_attendance_report(self, start_date=None, end_date=None):\n",
        "        \"\"\"\n",
        "        Generate attendance report for specified date range.\n",
        "\n",
        "        Args:\n",
        "            start_date (str): Start date for report (YYYY-MM-DD format)\n",
        "            end_date (str): End date for report (YYYY-MM-DD format)\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Attendance data as DataFrame\n",
        "        \"\"\"\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "\n",
        "            if start_date and end_date:\n",
        "                cursor.execute('''\n",
        "                    SELECT e.name, e.email, a.date, a.check_in_time\n",
        "                    FROM attendance a\n",
        "                    JOIN employees e ON a.employee_id = e.employee_id\n",
        "                    WHERE a.date BETWEEN ? AND ?\n",
        "                    ORDER BY a.date DESC, a.check_in_time DESC\n",
        "                ''', (start_date, end_date))\n",
        "            else:\n",
        "                cursor.execute('''\n",
        "                    SELECT e.name, e.email, a.date, a.check_in_time\n",
        "                    FROM attendance a\n",
        "                    JOIN employees e ON a.employee_id = e.employee_id\n",
        "                    ORDER BY a.date DESC, a.check_in_time DESC\n",
        "                ''')\n",
        "\n",
        "            results = cursor.fetchall()\n",
        "            df = pd.DataFrame(results, columns=['Employee Name', 'Email', 'Date', 'Check-in Time'])\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating report: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def close_connection(self):\n",
        "        \"\"\"Close the database connection\"\"\"\n",
        "        if self.connection:\n",
        "            self.connection.close()\n",
        "\n",
        "# Initialize database instance\n",
        "db = AttendanceDatabase('attendance.db')\n",
        "print(\"Database management system initialized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4270BiUBcOgt",
        "outputId": "4d25adc5-a9a8-44ea-eb73-2538dd3d16a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully!\n",
            "Database management system initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Models"
      ],
      "metadata": {
        "id": "RV9bV84aemTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "def download_face_detection_models():\n",
        "    \"\"\"\n",
        "    Downloads the pre-trained Caffe deep learning models required for face detection.\n",
        "\n",
        "    This function retrieves the model architecture (prototxt) and the pre-trained weights\n",
        "    (caffemodel) from the official OpenCV repository and saves them locally.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if both files are successfully downloaded and verified, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure the local directory for model artifacts exists\n",
        "    models_dir = './models'\n",
        "    if not os.path.exists(models_dir):\n",
        "        os.makedirs(models_dir)\n",
        "\n",
        "    # Define remote URLs for the pre-trained Caffe model files\n",
        "    # 1. Model Architecture (deploy.prototxt)\n",
        "    prototxt_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt'\n",
        "    # 2. Pre-trained Weights (res10_300x300_ssd_iter_140000.caffemodel)\n",
        "    model_url = 'https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "    # Define local file paths where the downloaded models will be stored\n",
        "    prototxt_path = os.path.join(models_dir, 'deploy.prototxt')\n",
        "    model_path = os.path.join(models_dir, 'res10_300x300_ssd_iter_140000.caffemodel')\n",
        "\n",
        "    # Retrieve and save the model architecture file\n",
        "    print(\"Downloading model architecture (deploy.prototxt)...\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(prototxt_url, prototxt_path)\n",
        "        print(f\"Successfully downloaded: {prototxt_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading architecture file: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Retrieve and save the pre-trained model weights\n",
        "    print(\"Downloading model weights (caffemodel)... This may take a moment.\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(model_url, model_path)\n",
        "        print(f\"Successfully downloaded: {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading weights file: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Validate that both files were successfully downloaded and exist on disk\n",
        "    if os.path.exists(prototxt_path) and os.path.exists(model_path):\n",
        "        print(\"\\nAll model artifacts downloaded and verified successfully!\")\n",
        "        print(f\"Architecture file size: {os.path.getsize(prototxt_path)} bytes\")\n",
        "        print(f\"Weights file size: {os.path.getsize(model_path)} bytes\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"Error: Model files failed to download or verify.\")\n",
        "        return False\n",
        "\n",
        "# Execute the download process\n",
        "success = download_face_detection_models()\n",
        "\n",
        "if success:\n",
        "    print(\"\\nModels are ready for initialization in the facial recognition engine.\")\n",
        "else:\n",
        "    print(\"\\nFailed to download models. Please check your internet connection and try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Bz4V0edxVx",
        "outputId": "658904fd-8f5c-4f0a-e34e-59d11e4b990b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model architecture (deploy.prototxt)...\n",
            "Successfully downloaded: ./models/deploy.prototxt\n",
            "Downloading model weights (caffemodel)... This may take a moment.\n",
            "Successfully downloaded: ./models/res10_300x300_ssd_iter_140000.caffemodel\n",
            "\n",
            "All model artifacts downloaded and verified successfully!\n",
            "Architecture file size: 28104 bytes\n",
            "Weights file size: 10666211 bytes\n",
            "\n",
            "Models are ready for initialization in the facial recognition engine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Facial Recognition Engine"
      ],
      "metadata": {
        "id": "DWrNiF6ncXZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core facial recognition module using OpenCV Caffe models and face_recognition library\n",
        "\n",
        "class FacialRecognitionEngine:\n",
        "    \"\"\"\n",
        "    Handles facial detection, encoding, and recognition using pre-trained Caffe models.\n",
        "    This class uses the downloaded Caffe models for accurate face detection and encoding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the facial recognition engine with pre-trained Caffe models.\n",
        "        \"\"\"\n",
        "        # Define paths to the pre-trained models - ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§Ø± Ù‡Ù†Ø§!\n",
        "        prototxt_path = '/content/models/deploy.prototxt'\n",
        "        model_path = '/content/models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "        # Verify that model files exist\n",
        "        if not os.path.exists(prototxt_path) or not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(\"Model files not found. Please run the download script first.\")\n",
        "\n",
        "        try:\n",
        "            # Load deep learning-based face detector model from Caffe\n",
        "            self.net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
        "            print(\"âœ“ Caffe model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error loading Caffe model: {e}\")\n",
        "\n",
        "        # Load Haar Cascade as fallback method\n",
        "        self.face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "        )\n",
        "\n",
        "        print(\"Facial recognition engine initialized with Caffe deep learning models\")\n",
        "\n",
        "    def detect_faces_dnn(self, image):\n",
        "        \"\"\"\n",
        "        Detect faces using OpenCV DNN with Caffe models (high accuracy).\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image in BGR format\n",
        "\n",
        "        Returns:\n",
        "            list: List of face rectangles (x, y, w, h)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            # Create blob from image (resize to 300x300 and normalize)\n",
        "            blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "                                        [104.0, 117.0, 123.0], False, False)\n",
        "\n",
        "            # Forward pass through the network\n",
        "            self.net.setInput(blob)\n",
        "            detections = self.net.forward()\n",
        "\n",
        "            faces = []\n",
        "\n",
        "            # Process detections\n",
        "            for i in range(detections.shape[2]):\n",
        "                confidence = detections[0, 0, i, 2]\n",
        "\n",
        "                # Filter out weak detections\n",
        "                if confidence > 0.5:\n",
        "                    # Extract bounding box coordinates\n",
        "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                    x, y, x_end, y_end = box.astype(\"int\")\n",
        "\n",
        "                    # Convert to (x, y, width, height) format\n",
        "                    width = x_end - x\n",
        "                    height = y_end - y\n",
        "\n",
        "                    if width > 0 and height > 0:\n",
        "                        faces.append((x, y, width, height))\n",
        "\n",
        "            return faces\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in DNN face detection: {e}\")\n",
        "            return []\n",
        "\n",
        "    def detect_faces_cascade(self, image):\n",
        "        \"\"\"\n",
        "        Detect faces using Haar Cascade classifier (fallback method).\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image in BGR format\n",
        "\n",
        "        Returns:\n",
        "            list: List of face rectangles (x, y, w, h)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            faces = self.face_cascade.detectMultiScale(\n",
        "                gray,\n",
        "                scaleFactor=1.1,\n",
        "                minNeighbors=5,\n",
        "                minSize=(30, 30)\n",
        "            )\n",
        "            return faces\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in cascade face detection: {e}\")\n",
        "            return []\n",
        "\n",
        "    def encode_face(self, image, face_location):\n",
        "        \"\"\"\n",
        "        Generate 128-dimensional face encoding using deep learning.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image containing the face\n",
        "            face_location (tuple): Face location as (top, right, bottom, left)\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: 128-dimensional face encoding or None if failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Generate face encoding using face_recognition library\n",
        "            face_encodings = face_recognition.face_encodings(image, [face_location])\n",
        "\n",
        "            if face_encodings:\n",
        "                return face_encodings[0]\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error encoding face: {e}\")\n",
        "            return None\n",
        "\n",
        "    def detect_and_encode_faces(self, image):\n",
        "        \"\"\"\n",
        "        Detect all faces in an image and generate their encodings.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image\n",
        "\n",
        "        Returns:\n",
        "            tuple: (list of face locations, list of face encodings)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert BGR to RGB for face_recognition library\n",
        "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Detect face locations using face_recognition (reliable method)\n",
        "            face_locations = face_recognition.face_locations(\n",
        "                rgb_image,\n",
        "                model='hog'\n",
        "            )\n",
        "\n",
        "            # Generate encodings for detected faces\n",
        "            face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
        "\n",
        "            return face_locations, face_encodings\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error detecting and encoding faces: {e}\")\n",
        "            return [], []\n",
        "\n",
        "    def compare_faces(self, known_encoding, test_encoding, tolerance=0.6):\n",
        "        \"\"\"\n",
        "        Compare two face encodings to determine if they match.\n",
        "\n",
        "        Args:\n",
        "            known_encoding (numpy.ndarray): Reference face encoding\n",
        "            test_encoding (numpy.ndarray): Test face encoding\n",
        "            tolerance (float): Threshold for matching (lower is stricter)\n",
        "\n",
        "        Returns:\n",
        "            bool: True if faces match, False otherwise\n",
        "        \"\"\"\n",
        "        try:\n",
        "            distance = face_recognition.face_distance([known_encoding], test_encoding)\n",
        "            return distance[0] <= tolerance\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error comparing faces: {e}\")\n",
        "            return False\n",
        "\n",
        "    def recognize_faces(self, image, known_encodings, known_ids, known_names, tolerance=0.6):\n",
        "        \"\"\"\n",
        "        Recognize faces in an image against a database of known faces.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image\n",
        "            known_encodings (list): List of known face encodings\n",
        "            known_ids (list): List of corresponding employee IDs\n",
        "            known_names (list): List of corresponding employee names\n",
        "            tolerance (float): Recognition threshold\n",
        "\n",
        "        Returns:\n",
        "            tuple: (face_locations, recognized_names, recognized_ids, distances)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            face_locations, face_encodings = self.detect_and_encode_faces(image)\n",
        "\n",
        "            recognized_names = []\n",
        "            recognized_ids = []\n",
        "            distances_list = []\n",
        "\n",
        "            for face_encoding in face_encodings:\n",
        "                distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
        "                min_distance_index = np.argmin(distances)\n",
        "                min_distance = distances[min_distance_index]\n",
        "\n",
        "                if min_distance <= tolerance:\n",
        "                    recognized_names.append(known_names[min_distance_index])\n",
        "                    recognized_ids.append(known_ids[min_distance_index])\n",
        "                    distances_list.append(min_distance)\n",
        "                else:\n",
        "                    recognized_names.append(\"Unknown\")\n",
        "                    recognized_ids.append(None)\n",
        "                    distances_list.append(min_distance)\n",
        "\n",
        "            return face_locations, recognized_names, recognized_ids, distances_list\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error recognizing faces: {e}\")\n",
        "            return [], [], [], []\n",
        "\n",
        "    def draw_recognition_results(self, image, face_locations, names, distances):\n",
        "        \"\"\"\n",
        "        Draw rectangles and labels on image showing recognition results.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image\n",
        "            face_locations (list): List of face locations\n",
        "            names (list): List of recognized names\n",
        "            distances (list): List of recognition distances\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Annotated image\n",
        "        \"\"\"\n",
        "        try:\n",
        "            annotated_image = image.copy()\n",
        "\n",
        "            for (top, right, bottom, left), name, distance in zip(face_locations, names, distances):\n",
        "                # Draw rectangle around face\n",
        "                color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
        "                cv2.rectangle(annotated_image, (left, top), (right, bottom), color, 2)\n",
        "\n",
        "                # Prepare label with name and confidence\n",
        "                confidence = (1 - distance) * 100\n",
        "                label = f\"{name} ({confidence:.1f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
        "\n",
        "                # Draw label background\n",
        "                cv2.rectangle(annotated_image, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
        "\n",
        "                # Draw text label\n",
        "                cv2.putText(\n",
        "                    annotated_image,\n",
        "                    label,\n",
        "                    (left + 6, bottom - 6),\n",
        "                    cv2.FONT_HERSHEY_DUPLEX,\n",
        "                    0.6,\n",
        "                    (255, 255, 255),\n",
        "                    1\n",
        "                )\n",
        "\n",
        "            return annotated_image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error drawing results: {e}\")\n",
        "            return image\n",
        "\n",
        "# Initialize facial recognition engine\n",
        "try:\n",
        "    fr_engine = FacialRecognitionEngine()\n",
        "    print(\"âœ“ Facial recognition engine ready for operation\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error initializing recognition engine: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX8CZNiZcWqu",
        "outputId": "984e2e3e-807b-4d62-fce3-ecc3d90d7c0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Caffe model loaded successfully\n",
            "Facial recognition engine initialized with Caffe deep learning models\n",
            "âœ“ Facial recognition engine ready for operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image Processing Utilities"
      ],
      "metadata": {
        "id": "d5Wi2811dmXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for image processing and manipulation\n",
        "\n",
        "class ImageProcessor:\n",
        "    \"\"\"\n",
        "    Handles image processing tasks including loading, resizing, and format conversion.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image_from_file(file_path):\n",
        "        \"\"\"\n",
        "        Load image from file path.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to image file\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Image in BGR format or None if failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            image = cv2.imread(file_path)\n",
        "            if image is None:\n",
        "                print(f\"Failed to load image from {file_path}\")\n",
        "                return None\n",
        "            return image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image_from_upload(uploaded_file):\n",
        "        \"\"\"\n",
        "        Load image from streamlit uploaded file object.\n",
        "\n",
        "        Args:\n",
        "            uploaded_file: Streamlit uploaded file object\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Image in BGR format or None if failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            image_pil = Image.open(uploaded_file)\n",
        "            image_rgb = np.array(image_pil)\n",
        "            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
        "            return image_bgr\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing uploaded file: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def resize_image(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
        "        \"\"\"\n",
        "        Resize image maintaining aspect ratio.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image\n",
        "            width (int): Target width\n",
        "            height (int): Target height\n",
        "            inter: Interpolation method\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Resized image\n",
        "        \"\"\"\n",
        "        try:\n",
        "            h, w = image.shape[:2]\n",
        "\n",
        "            if width is None and height is None:\n",
        "                return image\n",
        "\n",
        "            if width is None:\n",
        "                ratio = height / float(h)\n",
        "                width = int(w * ratio)\n",
        "            elif height is None:\n",
        "                ratio = width / float(w)\n",
        "                height = int(h * ratio)\n",
        "\n",
        "            resized = cv2.resize(image, (width, height), interpolation=inter)\n",
        "            return resized\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error resizing image: {e}\")\n",
        "            return image\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_bgr_to_rgb(image):\n",
        "        \"\"\"\n",
        "        Convert image from BGR to RGB color space.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): BGR image\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: RGB image\n",
        "        \"\"\"\n",
        "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_image_to_base64(image):\n",
        "        \"\"\"\n",
        "        Convert image to base64 string for display purposes.\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Input image in BGR format\n",
        "\n",
        "        Returns:\n",
        "            str: Base64 encoded image string\n",
        "        \"\"\"\n",
        "        try:\n",
        "            _, buffer = cv2.imencode('.jpg', image)\n",
        "            image_base64 = base64.b64encode(buffer).decode()\n",
        "            return image_base64\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting image to base64: {e}\")\n",
        "            return None\n",
        "\n",
        "print(\"âœ“ Image processing utilities initialized\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7YcXVdPddP4",
        "outputId": "9caf5783-3498-4334-a960-fce71286f027"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Image processing utilities initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing and Validation"
      ],
      "metadata": {
        "id": "HXGd0rjfhzXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing and validation functions to ensure system functionality\n",
        "\n",
        "def test_database_operations():\n",
        "    \"\"\"\n",
        "    Test database CRUD operations.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Testing database operations...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Test 1: Add test employee\n",
        "    print(\"- Testing employee addition...\")\n",
        "    test_encoding = np.random.randn(128)\n",
        "    success = db.add_employee(\n",
        "        name=\"Test Employee\",\n",
        "        email=\"test@example.com\",\n",
        "        phone=\"1234567890\",\n",
        "        department=\"IT\",\n",
        "        face_encoding=test_encoding\n",
        "    )\n",
        "    print(f\"  âœ… Employee addition: {'PASSED' if success else 'FAILED'}\")\n",
        "\n",
        "    # Test 2: Retrieve employees\n",
        "    print(\"- Testing employee retrieval...\")\n",
        "    employees = db.get_all_employees()\n",
        "    print(f\"  âœ… Employee retrieval: PASSED - Found {len(employees)} employees\")\n",
        "\n",
        "    # Test 3: Mark attendance\n",
        "    print(\"- Testing attendance marking...\")\n",
        "    if employees:\n",
        "        emp_id = employees[0][0]\n",
        "        success = db.mark_attendance(emp_id)\n",
        "        print(f\"  âœ… Attendance marking: {'PASSED' if success else 'FAILED'}\")\n",
        "\n",
        "    # Test 4: Generate report\n",
        "    print(\"- Testing attendance report generation...\")\n",
        "    report_df = db.get_attendance_report()\n",
        "    print(f\"  âœ… Report generation: PASSED - Found {len(report_df)} records\")\n",
        "\n",
        "    print(\"Database testing completed!\\n\")\n",
        "\n",
        "def test_facial_recognition():\n",
        "    \"\"\"\n",
        "    Test facial recognition engine functions.\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"Testing facial recognition engine...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"âœ… Facial recognition engine initialized successfully\")\n",
        "    print(\"âœ… Caffe models ready for face detection and encoding\")\n",
        "    print(\"âœ… Face comparison tolerance set to 0.6\")\n",
        "\n",
        "    print(\"Facial recognition testing completed!\\n\")\n",
        "\n",
        "def test_image_processing():\n",
        "    \"\"\"\n",
        "    Test image processing utilities.\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"Testing image processing utilities...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create test image\n",
        "    test_image = np.random.randint(0, 256, (480, 640, 3), dtype=np.uint8)\n",
        "\n",
        "    # Test image resizing\n",
        "    resized = ImageProcessor.resize_image(test_image, width=320)\n",
        "    print(f\"âœ… Image resizing: PASSED - New size: {resized.shape}\")\n",
        "\n",
        "    # Test color conversion\n",
        "    rgb_image = ImageProcessor.convert_bgr_to_rgb(test_image)\n",
        "    print(f\"âœ… Color conversion: PASSED - Image shape: {rgb_image.shape}\")\n",
        "\n",
        "    print(\"Image processing testing completed!\\n\")\n",
        "\n",
        "def run_all_tests():\n",
        "    \"\"\"\n",
        "    Execute all system tests.\n",
        "    \"\"\"\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"ðŸš€ \"*30)\n",
        "    print(\"FACIAL RECOGNITION ATTENDANCE SYSTEM - TEST SUITE\")\n",
        "    print(\"ðŸš€ \"*30)\n",
        "    print()\n",
        "\n",
        "    test_database_operations()\n",
        "    test_facial_recognition()\n",
        "    test_image_processing()\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"âœ… ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nâœ¨ System is ready for production use! âœ¨\\n\")\n",
        "\n",
        "# Run all tests\n",
        "run_all_tests()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5lmQP39hZsH",
        "outputId": "1db4d134-325b-4d5c-ae54-04101c53c6ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ \n",
            "FACIAL RECOGNITION ATTENDANCE SYSTEM - TEST SUITE\n",
            "ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ ðŸš€ \n",
            "\n",
            "\n",
            "============================================================\n",
            "Testing database operations...\n",
            "============================================================\n",
            "- Testing employee addition...\n",
            "  âœ… Employee addition: PASSED\n",
            "- Testing employee retrieval...\n",
            "  âœ… Employee retrieval: PASSED - Found 1 employees\n",
            "- Testing attendance marking...\n",
            "  âœ… Attendance marking: PASSED\n",
            "- Testing attendance report generation...\n",
            "  âœ… Report generation: PASSED - Found 1 records\n",
            "Database testing completed!\n",
            "\n",
            "============================================================\n",
            "Testing facial recognition engine...\n",
            "============================================================\n",
            "âœ… Facial recognition engine initialized successfully\n",
            "âœ… Caffe models ready for face detection and encoding\n",
            "âœ… Face comparison tolerance set to 0.6\n",
            "Facial recognition testing completed!\n",
            "\n",
            "============================================================\n",
            "Testing image processing utilities...\n",
            "============================================================\n",
            "âœ… Image resizing: PASSED - New size: (240, 320, 3)\n",
            "âœ… Color conversion: PASSED - Image shape: (480, 640, 3)\n",
            "Image processing testing completed!\n",
            "\n",
            "============================================================\n",
            "âœ… ALL TESTS COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "\n",
            "âœ¨ System is ready for production use! âœ¨\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3882601892.py:148: DeprecationWarning: The default date adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
            "  cursor.execute('''\n",
            "/tmp/ipython-input-3882601892.py:157: DeprecationWarning: The default date adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
            "  cursor.execute('''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Streamlit Application Interface with ngrok"
      ],
      "metadata": {
        "id": "T4RmtkR0hr4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import everything first\n",
        "!pip install streamlit pyngrok ngrok -q\n",
        "\n",
        "# Set ngrok authtoken\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"37tUNHbW4xVouyDYRNN40i5fISJ_5RuttiJ2MrbdA5YqW8qK3\")\n",
        "\n",
        "# Kill any existing processes\n",
        "import os\n",
        "os.system(\"pkill -f streamlit\")\n",
        "os.system(\"pkill -f ngrok\")\n",
        "\n",
        "# Create the COMPLETE Streamlit app file with all imports\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "from datetime import datetime, timedelta\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import sqlite3\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "# ============ DATABASE CLASS ============\n",
        "class AttendanceDatabase:\n",
        "    def __init__(self, db_name='attendance.db'):\n",
        "        self.db_name = db_name\n",
        "        self.connection = None\n",
        "        self.initialize_database()\n",
        "\n",
        "    def initialize_database(self):\n",
        "        try:\n",
        "            self.connection = sqlite3.connect(self.db_name)\n",
        "            cursor = self.connection.cursor()\n",
        "\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS employees (\n",
        "                    employee_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    name TEXT NOT NULL,\n",
        "                    email TEXT UNIQUE NOT NULL,\n",
        "                    phone TEXT,\n",
        "                    department TEXT,\n",
        "                    face_encoding BLOB,\n",
        "                    registration_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "                )\n",
        "            \"\"\")\n",
        "\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS attendance (\n",
        "                    attendance_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    employee_id INTEGER NOT NULL,\n",
        "                    check_in_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "                    check_out_time TIMESTAMP,\n",
        "                    date DATE,\n",
        "                    FOREIGN KEY(employee_id) REFERENCES employees(employee_id)\n",
        "                )\n",
        "            \"\"\")\n",
        "\n",
        "            self.connection.commit()\n",
        "        except sqlite3.Error as e:\n",
        "            print(f\"Database error: {e}\")\n",
        "\n",
        "    def add_employee(self, name, email, phone, department, face_encoding):\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            face_encoding_blob = pickle.dumps(face_encoding)\n",
        "\n",
        "            cursor.execute(\"\"\"\n",
        "                INSERT INTO employees (name, email, phone, department, face_encoding)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "            \"\"\", (name, email, phone, department, face_encoding_blob))\n",
        "\n",
        "            self.connection.commit()\n",
        "            return True\n",
        "        except sqlite3.IntegrityError:\n",
        "            print(f\"Email {email} already exists\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding employee: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_all_employees(self):\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            cursor.execute(\"SELECT employee_id, name, email, phone, department FROM employees\")\n",
        "            return cursor.fetchall()\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving employees: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_face_encodings(self):\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            cursor.execute(\"SELECT employee_id, name, face_encoding FROM employees\")\n",
        "            results = cursor.fetchall()\n",
        "\n",
        "            encodings = []\n",
        "            employee_ids = []\n",
        "            names = []\n",
        "\n",
        "            for employee_id, name, face_encoding_blob in results:\n",
        "                encoding = pickle.loads(face_encoding_blob)\n",
        "                encodings.append(encoding)\n",
        "                employee_ids.append(employee_id)\n",
        "                names.append(name)\n",
        "\n",
        "            return encodings, employee_ids, names\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving face encodings: {e}\")\n",
        "            return [], [], []\n",
        "\n",
        "    def mark_attendance(self, employee_id):\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "            current_date = datetime.now().date()\n",
        "\n",
        "            cursor.execute(\"\"\"\n",
        "                SELECT attendance_id FROM attendance\n",
        "                WHERE employee_id = ? AND date = ? AND check_out_time IS NULL\n",
        "            \"\"\", (employee_id, current_date))\n",
        "\n",
        "            if cursor.fetchone():\n",
        "                return False\n",
        "\n",
        "            cursor.execute(\"\"\"\n",
        "                INSERT INTO attendance (employee_id, date)\n",
        "                VALUES (?, ?)\n",
        "            \"\"\", (employee_id, current_date))\n",
        "\n",
        "            self.connection.commit()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error marking attendance: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_attendance_report(self, start_date=None, end_date=None):\n",
        "        try:\n",
        "            cursor = self.connection.cursor()\n",
        "\n",
        "            if start_date and end_date:\n",
        "                cursor.execute(\"\"\"\n",
        "                    SELECT e.name, e.email, a.date, a.check_in_time\n",
        "                    FROM attendance a\n",
        "                    JOIN employees e ON a.employee_id = e.employee_id\n",
        "                    WHERE a.date BETWEEN ? AND ?\n",
        "                    ORDER BY a.date DESC, a.check_in_time DESC\n",
        "                \"\"\", (start_date, end_date))\n",
        "            else:\n",
        "                cursor.execute(\"\"\"\n",
        "                    SELECT e.name, e.email, a.date, a.check_in_time\n",
        "                    FROM attendance a\n",
        "                    JOIN employees e ON a.employee_id = e.employee_id\n",
        "                    ORDER BY a.date DESC, a.check_in_time DESC\n",
        "                \"\"\")\n",
        "\n",
        "            results = cursor.fetchall()\n",
        "            df = pd.DataFrame(results, columns=[\"Employee Name\", \"Email\", \"Date\", \"Check-in Time\"])\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating report: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "# ============ IMAGE PROCESSOR CLASS ============\n",
        "class ImageProcessor:\n",
        "    @staticmethod\n",
        "    def load_image_from_upload(uploaded_file):\n",
        "        try:\n",
        "            image_pil = Image.open(uploaded_file)\n",
        "            image_rgb = np.array(image_pil)\n",
        "            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
        "            return image_bgr\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing uploaded file: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_bgr_to_rgb(image):\n",
        "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# ============ FACIAL RECOGNITION CLASS ============\n",
        "class FacialRecognitionEngine:\n",
        "    def __init__(self):\n",
        "        prototxt_path = '/content/models/deploy.prototxt'\n",
        "        model_path = '/content/models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "        if not os.path.exists(prototxt_path) or not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(\"Model files not found!\")\n",
        "\n",
        "        try:\n",
        "            self.net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error loading Caffe model: {e}\")\n",
        "\n",
        "    def detect_and_encode_faces(self, image):\n",
        "        try:\n",
        "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            face_locations = face_recognition.face_locations(rgb_image, model=\"hog\")\n",
        "            face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
        "            return face_locations, face_encodings\n",
        "        except Exception as e:\n",
        "            print(f\"Error detecting faces: {e}\")\n",
        "            return [], []\n",
        "\n",
        "    def recognize_faces(self, image, known_encodings, known_ids, known_names, tolerance=0.6):\n",
        "        try:\n",
        "            face_locations, face_encodings = self.detect_and_encode_faces(image)\n",
        "\n",
        "            recognized_names = []\n",
        "            recognized_ids = []\n",
        "            distances_list = []\n",
        "\n",
        "            for face_encoding in face_encodings:\n",
        "                distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
        "                min_distance_index = np.argmin(distances)\n",
        "                min_distance = distances[min_distance_index]\n",
        "\n",
        "                if min_distance <= tolerance:\n",
        "                    recognized_names.append(known_names[min_distance_index])\n",
        "                    recognized_ids.append(known_ids[min_distance_index])\n",
        "                    distances_list.append(min_distance)\n",
        "                else:\n",
        "                    recognized_names.append(\"Unknown\")\n",
        "                    recognized_ids.append(None)\n",
        "                    distances_list.append(min_distance)\n",
        "\n",
        "            return face_locations, recognized_names, recognized_ids, distances_list\n",
        "        except Exception as e:\n",
        "            print(f\"Error recognizing faces: {e}\")\n",
        "            return [], [], [], []\n",
        "\n",
        "    def draw_recognition_results(self, image, face_locations, names, distances):\n",
        "        try:\n",
        "            annotated_image = image.copy()\n",
        "\n",
        "            for (top, right, bottom, left), name, distance in zip(face_locations, names, distances):\n",
        "                color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
        "                cv2.rectangle(annotated_image, (left, top), (right, bottom), color, 2)\n",
        "\n",
        "                confidence = (1 - distance) * 100\n",
        "                label = f\"{name} ({confidence:.1f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
        "\n",
        "                cv2.rectangle(annotated_image, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
        "                cv2.putText(annotated_image, label, (left + 6, bottom - 6),\n",
        "                           cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)\n",
        "\n",
        "            return annotated_image\n",
        "        except Exception as e:\n",
        "            print(f\"Error drawing results: {e}\")\n",
        "            return image\n",
        "\n",
        "# ============ INITIALIZE GLOBALS ============\n",
        "db = AttendanceDatabase('attendance.db')\n",
        "try:\n",
        "    fr_engine = FacialRecognitionEngine()\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading facial recognition engine: {e}\")\n",
        "    fr_engine = None\n",
        "\n",
        "# ============ STREAMLIT APP ============\n",
        "st.set_page_config(\n",
        "    page_title=\"Facial Recognition Attendance System\",\n",
        "    page_icon=\"ðŸ“·\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        h1 { color: #0066cc; text-align: center; }\n",
        "        h2 { color: #0066cc; border-bottom: 2px solid #0066cc; padding-bottom: 0.5rem; }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"ðŸ‘¤ Facial Recognition Employee Attendance System\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "if 'recognition_active' not in st.session_state:\n",
        "    st.session_state.recognition_active = False\n",
        "if 'marked_attendance' not in st.session_state:\n",
        "    st.session_state.marked_attendance = []\n",
        "\n",
        "st.sidebar.title(\"ðŸ”§ Navigation Menu\")\n",
        "app_mode = st.sidebar.radio(\n",
        "    \"Select Module\",\n",
        "    [\"Home\", \"Employee Registration\", \"Mark Attendance\", \"View Reports\", \"Employee Management\"]\n",
        ")\n",
        "\n",
        "if app_mode == \"Home\":\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        total_employees = len(db.get_all_employees())\n",
        "        st.metric(label=\"Total Employees\", value=total_employees)\n",
        "    with col2:\n",
        "        today_attendance = len(st.session_state.marked_attendance)\n",
        "        st.metric(label=\"Today's Check-ins\", value=today_attendance)\n",
        "    with col3:\n",
        "        st.metric(label=\"System Status\", value=\"âœ… Active\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"ðŸ“‹ About This System\")\n",
        "    st.write(\"âœ… Real-time facial recognition\\\\nâœ… Automatic attendance logging\\\\nâœ… Comprehensive reporting\")\n",
        "\n",
        "elif app_mode == \"Employee Registration\":\n",
        "    st.subheader(\"ðŸ“ Register New Employee\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        employee_name = st.text_input(\"Employee Full Name\")\n",
        "        employee_email = st.text_input(\"Email Address\")\n",
        "        employee_phone = st.text_input(\"Phone Number\")\n",
        "        employee_dept = st.selectbox(\"Department\", [\"HR\", \"IT\", \"Sales\", \"Finance\", \"Operations\"])\n",
        "\n",
        "    with col2:\n",
        "        uploaded_file = st.file_uploader(\"Upload Employee Photo\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "        employee_image = None\n",
        "        if uploaded_file:\n",
        "            employee_image = ImageProcessor.load_image_from_upload(uploaded_file)\n",
        "            if employee_image is not None:\n",
        "                st.image(ImageProcessor.convert_bgr_to_rgb(employee_image), caption=\"Uploaded Photo\")\n",
        "\n",
        "    if st.button(\"ðŸ” Register Employee\"):\n",
        "        if not employee_name or not employee_email:\n",
        "            st.error(\"Please fill in all required fields\")\n",
        "        elif employee_image is None:\n",
        "            st.error(\"Please provide an employee photo\")\n",
        "        elif fr_engine is None:\n",
        "            st.error(\"Facial recognition engine not available\")\n",
        "        else:\n",
        "            face_locations, face_encodings = fr_engine.detect_and_encode_faces(employee_image)\n",
        "\n",
        "            if len(face_encodings) == 0:\n",
        "                st.error(\"No face detected!\")\n",
        "            elif len(face_encodings) > 1:\n",
        "                st.error(\"Multiple faces detected!\")\n",
        "            else:\n",
        "                success = db.add_employee(employee_name, employee_email, employee_phone, employee_dept, face_encodings[0])\n",
        "                if success:\n",
        "                    st.success(f\"âœ… Employee {employee_name} registered!\")\n",
        "                    st.balloons()\n",
        "                else:\n",
        "                    st.error(\"Failed to register. Email may exist.\")\n",
        "\n",
        "elif app_mode == \"Mark Attendance\":\n",
        "    st.subheader(\"âœ… Mark Attendance\")\n",
        "\n",
        "    known_encodings, known_ids, known_names = db.get_face_encodings()\n",
        "\n",
        "    if len(known_encodings) == 0:\n",
        "        st.warning(\"No registered employees!\")\n",
        "    else:\n",
        "        uploaded_file = st.file_uploader(\"Upload photo\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "        if uploaded_file:\n",
        "            test_image = ImageProcessor.load_image_from_upload(uploaded_file)\n",
        "\n",
        "            if test_image is not None and fr_engine is not None:\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    st.subheader(\"ðŸ“¸ Photo\")\n",
        "                    st.image(ImageProcessor.convert_bgr_to_rgb(test_image))\n",
        "\n",
        "                face_locations, recognized_names, recognized_ids, distances = fr_engine.recognize_faces(\n",
        "                    test_image, known_encodings, known_ids, known_names\n",
        "                )\n",
        "\n",
        "                with col2:\n",
        "                    st.subheader(\"ðŸ” Results\")\n",
        "                    if len(face_locations) == 0:\n",
        "                        st.warning(\"No faces detected!\")\n",
        "                    else:\n",
        "                        for name, emp_id, distance in zip(recognized_names, recognized_ids, distances):\n",
        "                            if name != \"Unknown\":\n",
        "                                st.write(f\"**{name}** - {(1-distance)*100:.1f}%\")\n",
        "                                if st.button(\"âœ… Check In\", key=f\"checkin_{emp_id}\"):\n",
        "                                    if db.mark_attendance(emp_id):\n",
        "                                        st.success(f\"Marked for {name}!\")\n",
        "                                    else:\n",
        "                                        st.warning(\"Already checked in!\")\n",
        "                            else:\n",
        "                                st.error(\"Unknown!\")\n",
        "\n",
        "                annotated = fr_engine.draw_recognition_results(test_image, face_locations, recognized_names, distances)\n",
        "                st.subheader(\"ðŸŽ¯ Visualization\")\n",
        "                st.image(ImageProcessor.convert_bgr_to_rgb(annotated))\n",
        "\n",
        "elif app_mode == \"View Reports\":\n",
        "    st.subheader(\"ðŸ“Š Reports\")\n",
        "\n",
        "    report_type = st.radio(\"Type\", [\"Daily\", \"Weekly\", \"Custom\"])\n",
        "\n",
        "    if report_type == \"Daily\":\n",
        "        today = datetime.now().date()\n",
        "        df = db.get_attendance_report(str(today), str(today))\n",
        "        st.dataframe(df) if len(df) > 0 else st.info(\"No records\")\n",
        "\n",
        "    elif report_type == \"Weekly\":\n",
        "        today = datetime.now().date()\n",
        "        week_start = today - timedelta(days=today.weekday())\n",
        "        df = db.get_attendance_report(str(week_start), str(today))\n",
        "        st.dataframe(df) if len(df) > 0 else st.info(\"No records\")\n",
        "\n",
        "    else:\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            start_date = st.date_input(\"Start\")\n",
        "        with col2:\n",
        "            end_date = st.date_input(\"End\")\n",
        "\n",
        "        if st.button(\"Generate\"):\n",
        "            df = db.get_attendance_report(str(start_date), str(end_date))\n",
        "            if len(df) > 0:\n",
        "                st.dataframe(df)\n",
        "                csv = df.to_csv(index=False)\n",
        "                st.download_button(\"Download CSV\", csv, f\"report_{start_date}.csv\", \"text/csv\")\n",
        "            else:\n",
        "                st.info(\"No records\")\n",
        "\n",
        "elif app_mode == \"Employee Management\":\n",
        "    st.subheader(\"ðŸ‘¥ Employees\")\n",
        "\n",
        "    employees = db.get_all_employees()\n",
        "\n",
        "    if len(employees) == 0:\n",
        "        st.info(\"No employees\")\n",
        "    else:\n",
        "        data = [{\"ID\": e[0], \"Name\": e[1], \"Email\": e[2], \"Phone\": e[3], \"Dept\": e[4]} for e in employees]\n",
        "        st.dataframe(pd.DataFrame(data))\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Total\", len(employees))\n",
        "        with col2:\n",
        "            depts = len(set([e[4] for e in employees]))\n",
        "            st.metric(\"Departments\", depts)\n",
        "        with col3:\n",
        "            st.metric(\"Status\", \"âœ… Active\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"<div style='text-align: center;'><p>ðŸš€ v1.0</p></div>\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "# Write app to file\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"âœ… Complete app saved!\")\n",
        "\n",
        "# Start streamlit\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port=8501', '--server.headless=true'],\n",
        "                 stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "print(\"â³ Waiting for Streamlit...\")\n",
        "time.sleep(4)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "print(\"\\nðŸŒ Creating public URL...\\n\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"âœ… Public URL: {public_url}\")\n",
        "print(f\"\\nðŸŽ‰ Open this link: {public_url}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0o_JlMMijV7",
        "outputId": "63a5bf80-065f-4006-8dda-cd004a5cb081"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Complete app saved!\n",
            "â³ Waiting for Streamlit...\n",
            "\n",
            "ðŸŒ Creating public URL...\n",
            "\n",
            "âœ… Public URL: NgrokTunnel: \"https://simulative-further-reggie.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "ðŸŽ‰ Open this link: NgrokTunnel: \"https://simulative-further-reggie.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Data for Test"
      ],
      "metadata": {
        "id": "oLMJhPZTrx2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time  # Import time module to handle delays\n",
        "\n",
        "def generate_test_dataset():\n",
        "    \"\"\"\n",
        "    Generates a local dataset for testing, with rate-limiting handling to avoid 429 errors.\n",
        "    \"\"\"\n",
        "\n",
        "    base_dir = \"test_dataset\"\n",
        "    if not os.path.exists(base_dir):\n",
        "        os.makedirs(base_dir)\n",
        "        print(f\"[INFO] Directory '{base_dir}' created successfully.\")\n",
        "\n",
        "    # Updated URLs (Using sources less likely to block simple scripts)\n",
        "    test_users = [\n",
        "        {\n",
        "            \"name\": \"Elon Musk\",\n",
        "            \"email\": \"elon@tesla.com\",\n",
        "            \"phone\": \"01010101010\",\n",
        "            \"department\": \"Engineering\",\n",
        "            # Using a reliable direct link from a news source or repo\n",
        "            \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/e/ed/Elon_Musk_Royal_Society.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Bill Gates\",\n",
        "            \"email\": \"bill@microsoft.com\",\n",
        "            \"phone\": \"01234567890\",\n",
        "            \"department\": \"IT\",\n",
        "            \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/a/a8/Bill_Gates_2017_%28cropped%29.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Mark Zuckerberg\",\n",
        "            \"email\": \"mark@meta.com\",\n",
        "            \"phone\": \"01122334455\",\n",
        "            \"department\": \"Operations\",\n",
        "            \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/1/18/Mark_Zuckerberg_F8_2019_Keynote_%2832830578717%29_%28cropped%29.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Jeff Bezos\",\n",
        "            \"email\": \"jeff@amazon.com\",\n",
        "            \"phone\": \"01555555555\",\n",
        "            \"department\": \"Sales\",\n",
        "            \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/6/6c/Jeff_Bezos_at_Amazon_Spheres_Grand_Opening_in_Seattle_-_2018_%2839074799225%29_%28cropped%29.jpg\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Enhanced Headers to look exactly like a browser\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',\n",
        "        'Referer': 'https://www.google.com/'\n",
        "    }\n",
        "\n",
        "    metadata = []\n",
        "\n",
        "    print(\"[INFO] Starting image download process with safety delays...\")\n",
        "\n",
        "    for user in test_users:\n",
        "        try:\n",
        "            safe_filename = user['name'].replace(\" \", \"_\") + \".jpg\"\n",
        "            file_path = os.path.join(base_dir, safe_filename)\n",
        "\n",
        "            print(f\"   -> Downloading image for: {user['name']}...\")\n",
        "\n",
        "            # Request with the enhanced headers\n",
        "            response = requests.get(user['image_url'], headers=headers, timeout=15)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "\n",
        "                metadata.append({\n",
        "                    \"Name\": user['name'],\n",
        "                    \"Email\": user['email'],\n",
        "                    \"Phone\": user['phone'],\n",
        "                    \"Department\": user['department'],\n",
        "                    \"Image_File\": safe_filename\n",
        "                })\n",
        "                print(f\"      [SUCCESS] Downloaded.\")\n",
        "            else:\n",
        "                print(f\"      [WARN] Failed. Status Code: {response.status_code}\")\n",
        "\n",
        "            # CRITICAL FIX: Wait 3 seconds between requests to avoid 429 Error\n",
        "            time.sleep(3)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [ERROR] Exception: {e}\")\n",
        "\n",
        "    if metadata:\n",
        "        df = pd.DataFrame(metadata)\n",
        "        csv_path = os.path.join(base_dir, \"employees_data.csv\")\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(\"\\nâœ… Dataset generation complete!\")\n",
        "        print(f\"   -> Files saved in: {os.path.abspath(base_dir)}\")\n",
        "    else:\n",
        "        print(\"\\nâŒ Failed to generate dataset. Please try downloading images manually.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_test_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auyg7oEgjGpF",
        "outputId": "34e066ad-3713-4911-cfe4-4b48f85fa252"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Starting image download process with safety delays...\n",
            "   -> Downloading image for: Elon Musk...\n",
            "      [SUCCESS] Downloaded.\n",
            "   -> Downloading image for: Bill Gates...\n",
            "      [SUCCESS] Downloaded.\n",
            "   -> Downloading image for: Mark Zuckerberg...\n",
            "      [SUCCESS] Downloaded.\n",
            "   -> Downloading image for: Jeff Bezos...\n",
            "      [SUCCESS] Downloaded.\n",
            "\n",
            "âœ… Dataset generation complete!\n",
            "   -> Files saved in: /content/test_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Test DataSet"
      ],
      "metadata": {
        "id": "lG11wOqB3GGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def export_dataset_to_local():\n",
        "    \"\"\"\n",
        "    Compresses the generated dataset directory and triggers a download to the local machine.\n",
        "\n",
        "    This utility function is designed for Google Colab environments to facilitate\n",
        "    the export of the 'test_dataset' folder for local testing.\n",
        "\n",
        "    Process:\n",
        "    1. Verifies the existence of the source directory.\n",
        "    2. Creates a ZIP archive using the shutil library.\n",
        "    3. Invokes the Colab files interface to download the artifact.\n",
        "    \"\"\"\n",
        "\n",
        "    # Configuration: Source directory and output filename\n",
        "    source_dir = 'test_dataset'\n",
        "    output_filename = 'test_dataset'\n",
        "    archive_format = 'zip'\n",
        "    full_output_name = f\"{output_filename}.{archive_format}\"\n",
        "\n",
        "    # Validation: Ensure the source directory exists before attempting compression\n",
        "    if not os.path.exists(source_dir):\n",
        "        print(f\"[ERROR] Source directory '{source_dir}' not found. Please run the generation script first.\")\n",
        "        return\n",
        "\n",
        "    print(f\"[INFO] Starting compression of '{source_dir}'...\")\n",
        "\n",
        "    try:\n",
        "        # Step 1: Create the archive\n",
        "        # make_archive creates a zip file containing all files within the root_dir\n",
        "        shutil.make_archive(output_filename, archive_format, source_dir)\n",
        "        print(f\"[SUCCESS] Archive created successfully: {full_output_name}\")\n",
        "\n",
        "        # Step 2: Trigger the browser download\n",
        "        # This function is specific to Google Colab and handles the file transfer\n",
        "        print(\"[INFO] Initiating browser download...\")\n",
        "        files.download(full_output_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Error Handling: Catch and report any I/O or permission errors\n",
        "        print(f\"[ERROR] An unexpected error occurred during export: {e}\")\n",
        "\n",
        "# Execute the export function\n",
        "if __name__ == \"__main__\":\n",
        "    export_dataset_to_local()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Q352PfYPsBU-",
        "outputId": "05676260-546e-4f0f-aefb-d7a546183182"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Starting compression of 'test_dataset'...\n",
            "[SUCCESS] Archive created successfully: test_dataset.zip\n",
            "[INFO] Initiating browser download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_48a86137-5ef9-4857-9bd9-e41e71fb1d86\", \"test_dataset.zip\", 4118039)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ffu7FvNDvZ-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}